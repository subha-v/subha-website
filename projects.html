<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - Subha Vadlamannati</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <nav>
        <a href="index.html">About</a>
        <a href="projects.html">Projects</a>
        <a href="blog.html">Blog</a>
    </nav>

    <main>
        <h1>Projects & Research</h1>

        <div class="project">
            <h3>SPRUCE: Multi-resolution Satellite Fusion for Canopy Height Prediction </h3>
            <p>
                
                We designed a multi-resolution fusion CNN that replaces proprietary imagery with open-access Sentinel-1 SAR and Sentinel-2 multispectral data to predict forest canopy height. To process over 7 million samples (3TB+) efficiently, we built a distributed training pipeline using PyTorch DDP across 8 NVIDIA B200 GPUs, implementing mixed precision training and spatial cross-validation to prevent data leakage. The resulting model achieved a Mean Absolute Error of 5.08m, outperforming our single-resolution baseline by 44% and demonstrating a scalable approach to global biomass monitoring.
            </p>
            <p><a href="https://drive.google.com/file/d/1mSdYwDoE8I80L3nHbKaP1E4GCJ-dVptE/view?usp=sharing">Paper</a></p>
        </div>

        <div class="project">
            <h3>HILITe: Human-AI Collaborative Framework for Image Transcreation (EMNLP HCI+NLP 2025)</h3>
            <p>
                Co-authored an open-source framework that localizes images for cultural relevance by routing requests across 6 specialized diffusion models via a VLM reasoning engine. By integrating human-in-the-loop feedback from translators across seven countries, we built a system that outperforms DALL-E 3, achieving a 25.7% improvement in accuracy over automated baselines. The platform leverages ensemble modeling and reference-based masking to overcome the "cultural bottleneck" in standard AI, providing a scalable solution for authentic, cross-cultural content adaptation.

            </p>
            <p><a href="https://platform.opennlplabs.org/">View Project</a> | <a href="https://ieeexplore.ieee.org/document/10825916">Paper</a></p>
        </div>

        <div class="project">
            <h3>Optimized B200 Matrix Multiplication</h3>
            <p>
                Built a high-performance matrix multiplication kernel for NVIDIA's B200 GPU achieving ~1200 TFLOPs. Implemented persistent kernels with multi-stage pipelining using a circular buffer, leveraging the Tensor Memory Accelerator (TMA) for efficient global-to-shared memory transfers and the new Blackwell TMEM for tensor core accumulation. Used BF16 inputs with FP32 accumulation and optimized synchronization patterns between producer and consumer warps.
            </p>
            <p><a href="blog/b200-matmul.html">Read More</a></p>
        </div>

        More coming soon!

    </main>

    <footer>
        <p>&copy; 2025 Subha Vadlamannati</p>
    </footer>
</body>
</html>
